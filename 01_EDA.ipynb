{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hi team,\n",
    "\n",
    "In this notebook, I have conducted an extensive exploratory data analysis (EDA) using the provided `train.csv` file. EDA is a critical step in any data science project as it allows us to explore the dataset, scrutinize its characteristics, and uncover insights that guide data preparation and model development.\n",
    "\n",
    "To build a strong foundation, I also relied on external sources to understand key concepts related to **preventive care** and **chronic disease detection**, aligning the analysis with the project's objective of identifying patterns and actionable insights.\n",
    "\n",
    "#### Key Steps in the Analysis:\n",
    "1. **Dataset Loading and Overview**:\n",
    "   - I used the pandas library to import and explore the dataset, examining its dimensions and structure. \n",
    "   - Initial summaries and descriptive statistics provided an overview of numerical and categorical features.\n",
    "\n",
    "2. **Automated EDA with Sweetviz**:\n",
    "   - Leveraged the Sweetviz library to automate EDA and generate an interactive HTML report. This report quickly highlighted key dataset characteristics, such as feature distributions, correlations, and missing values.\n",
    "   - The Sweetviz report played a pivotal role in identifying potential preprocessing needs, such as handling missing data and feature engineering.\n",
    "\n",
    "3. **Handling Missing Values**:\n",
    "   - Identified columns with high percentages of missing values and made data-driven decisions to either drop or impute missing entries.\n",
    "\n",
    "4. **Insights for Model Preparation**:\n",
    "   - Key observations from this notebook will inform the next steps, such as feature engineering and model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexi\\OneDrive\\Desktop\\Github\\Xtillion\\Xtillion_assessment\\project_Xtillion\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries loaded!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neptune\n",
    "import sweetviz as sv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"All libraries loaded!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code are used to:\n",
    "1. **Check the dataset dimensions** (`df.shape`).\n",
    "2. **Preview the dataset** to understand its structure and content (`df.head()`).\n",
    "3. **Generate descriptive statistics** for numerical columns (`df.describe()`), which helps understand the distribution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275236, 44)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimensions of the DataFrame (number of rows and columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Income_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Employment_Status</th>\n",
       "      <th>Number_of_Children</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>...</th>\n",
       "      <th>Last_Routine_Checkup</th>\n",
       "      <th>Tetanus_Shot_Status</th>\n",
       "      <th>Colonoscopy_Status</th>\n",
       "      <th>Mammogram_Status</th>\n",
       "      <th>PSA_Test_Status</th>\n",
       "      <th>Flu_Shot_Status</th>\n",
       "      <th>Eye_Exam_Status</th>\n",
       "      <th>Last_Dental_Visit</th>\n",
       "      <th>Veteran_Status</th>\n",
       "      <th>Chronic_Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  Race  Education_Level  Income_Level  Marital_Status  \\\n",
       "0   66    1     1              4.0          99.0             1.0   \n",
       "1   74    1     1              6.0           7.0             1.0   \n",
       "2   61    1     2              4.0           5.0             5.0   \n",
       "3   44    2     1              6.0           3.0             5.0   \n",
       "4   79    1     7              2.0           5.0             6.0   \n",
       "\n",
       "   Employment_Status  Number_of_Children  Weight  Height  ...  \\\n",
       "0                1.0                88.0   220.0   603.0  ...   \n",
       "1                7.0                88.0   170.0   511.0  ...   \n",
       "2                8.0                88.0   170.0   511.0  ...   \n",
       "3                1.0                88.0   150.0   502.0  ...   \n",
       "4                5.0                10.0   275.0   507.0  ...   \n",
       "\n",
       "   Last_Routine_Checkup  Tetanus_Shot_Status  Colonoscopy_Status  \\\n",
       "0                   1.0                  4.0                 1.0   \n",
       "1                   1.0                  3.0                 1.0   \n",
       "2                   7.0                  4.0                 2.0   \n",
       "3                   2.0                  4.0                 NaN   \n",
       "4                   3.0                  NaN                 1.0   \n",
       "\n",
       "   Mammogram_Status  PSA_Test_Status  Flu_Shot_Status  Eye_Exam_Status  \\\n",
       "0               NaN              NaN              2.0              NaN   \n",
       "1               NaN              NaN              1.0              NaN   \n",
       "2               NaN              NaN              2.0              NaN   \n",
       "3               2.0              NaN              1.0              NaN   \n",
       "4               NaN              NaN              NaN              NaN   \n",
       "\n",
       "   Last_Dental_Visit  Veteran_Status  Chronic_Condition  \n",
       "0                2.0             2.0                3.0  \n",
       "1                1.0             1.0                3.0  \n",
       "2                7.0             1.0                3.0  \n",
       "3                4.0             2.0                3.0  \n",
       "4                3.0             2.0                1.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows of the DataFrame to understand its structure and contents\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Income_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Employment_Status</th>\n",
       "      <th>Number_of_Children</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>...</th>\n",
       "      <th>Last_Routine_Checkup</th>\n",
       "      <th>Tetanus_Shot_Status</th>\n",
       "      <th>Colonoscopy_Status</th>\n",
       "      <th>Mammogram_Status</th>\n",
       "      <th>PSA_Test_Status</th>\n",
       "      <th>Flu_Shot_Status</th>\n",
       "      <th>Eye_Exam_Status</th>\n",
       "      <th>Last_Dental_Visit</th>\n",
       "      <th>Veteran_Status</th>\n",
       "      <th>Chronic_Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>275236.000000</td>\n",
       "      <td>275236.000000</td>\n",
       "      <td>275236.000000</td>\n",
       "      <td>275235.000000</td>\n",
       "      <td>267285.000000</td>\n",
       "      <td>275234.000000</td>\n",
       "      <td>271388.000000</td>\n",
       "      <td>269475.000000</td>\n",
       "      <td>265485.000000</td>\n",
       "      <td>264803.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>275236.000000</td>\n",
       "      <td>247391.000000</td>\n",
       "      <td>179415.000000</td>\n",
       "      <td>137219.000000</td>\n",
       "      <td>4610.000000</td>\n",
       "      <td>248494.000000</td>\n",
       "      <td>10051.000000</td>\n",
       "      <td>274382.000000</td>\n",
       "      <td>272652.000000</td>\n",
       "      <td>275236.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>55.344355</td>\n",
       "      <td>1.529934</td>\n",
       "      <td>1.918950</td>\n",
       "      <td>5.047697</td>\n",
       "      <td>22.549402</td>\n",
       "      <td>2.405448</td>\n",
       "      <td>3.916393</td>\n",
       "      <td>67.001974</td>\n",
       "      <td>780.393687</td>\n",
       "      <td>823.406389</td>\n",
       "      <td>...</td>\n",
       "      <td>1.438198</td>\n",
       "      <td>3.113351</td>\n",
       "      <td>1.269883</td>\n",
       "      <td>1.248661</td>\n",
       "      <td>1.786551</td>\n",
       "      <td>1.519618</td>\n",
       "      <td>2.411203</td>\n",
       "      <td>1.768250</td>\n",
       "      <td>1.897276</td>\n",
       "      <td>2.633329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.592387</td>\n",
       "      <td>0.499104</td>\n",
       "      <td>1.924496</td>\n",
       "      <td>1.045934</td>\n",
       "      <td>32.867302</td>\n",
       "      <td>1.813631</td>\n",
       "      <td>2.900939</td>\n",
       "      <td>37.132558</td>\n",
       "      <td>2268.496758</td>\n",
       "      <td>1600.589501</td>\n",
       "      <td>...</td>\n",
       "      <td>1.113077</td>\n",
       "      <td>1.695932</td>\n",
       "      <td>0.443900</td>\n",
       "      <td>0.633706</td>\n",
       "      <td>1.508633</td>\n",
       "      <td>0.749518</td>\n",
       "      <td>1.571180</td>\n",
       "      <td>1.325203</td>\n",
       "      <td>0.499729</td>\n",
       "      <td>0.766646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>511.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Age            Sex           Race  Education_Level  \\\n",
       "count  275236.000000  275236.000000  275236.000000    275235.000000   \n",
       "mean       55.344355       1.529934       1.918950         5.047697   \n",
       "std        17.592387       0.499104       1.924496         1.045934   \n",
       "min        18.000000       1.000000       1.000000         1.000000   \n",
       "25%        41.000000       1.000000       1.000000         4.000000   \n",
       "50%        58.000000       2.000000       1.000000         5.000000   \n",
       "75%        70.000000       2.000000       2.000000         6.000000   \n",
       "max        80.000000       2.000000       7.000000         9.000000   \n",
       "\n",
       "        Income_Level  Marital_Status  Employment_Status  Number_of_Children  \\\n",
       "count  267285.000000   275234.000000      271388.000000       269475.000000   \n",
       "mean       22.549402        2.405448           3.916393           67.001974   \n",
       "std        32.867302        1.813631           2.900939           37.132558   \n",
       "min         1.000000        1.000000           1.000000            1.000000   \n",
       "25%         6.000000        1.000000           1.000000           88.000000   \n",
       "50%         8.000000        1.000000           2.000000           88.000000   \n",
       "75%        10.000000        3.000000           7.000000           88.000000   \n",
       "max        99.000000        9.000000           9.000000           99.000000   \n",
       "\n",
       "              Weight         Height  ...  Last_Routine_Checkup  \\\n",
       "count  265485.000000  264803.000000  ...         275236.000000   \n",
       "mean      780.393687     823.406389  ...              1.438198   \n",
       "std      2268.496758    1600.589501  ...              1.113077   \n",
       "min        32.000000     209.000000  ...              1.000000   \n",
       "25%       150.000000     504.000000  ...              1.000000   \n",
       "50%       180.000000     507.000000  ...              1.000000   \n",
       "75%       220.000000     511.000000  ...              1.000000   \n",
       "max      9999.000000    9999.000000  ...              9.000000   \n",
       "\n",
       "       Tetanus_Shot_Status  Colonoscopy_Status  Mammogram_Status  \\\n",
       "count        247391.000000       179415.000000     137219.000000   \n",
       "mean              3.113351            1.269883          1.248661   \n",
       "std               1.695932            0.443900          0.633706   \n",
       "min               1.000000            1.000000          1.000000   \n",
       "25%               2.000000            1.000000          1.000000   \n",
       "50%               3.000000            1.000000          1.000000   \n",
       "75%               4.000000            2.000000          1.000000   \n",
       "max               9.000000            2.000000          9.000000   \n",
       "\n",
       "       PSA_Test_Status  Flu_Shot_Status  Eye_Exam_Status  Last_Dental_Visit  \\\n",
       "count      4610.000000    248494.000000     10051.000000      274382.000000   \n",
       "mean          1.786551         1.519618         2.411203           1.768250   \n",
       "std           1.508633         0.749518         1.571180           1.325203   \n",
       "min           1.000000         1.000000         1.000000           1.000000   \n",
       "25%           1.000000         1.000000         1.000000           1.000000   \n",
       "50%           1.000000         1.000000         2.000000           1.000000   \n",
       "75%           2.000000         2.000000         3.000000           2.000000   \n",
       "max           9.000000         9.000000         9.000000           9.000000   \n",
       "\n",
       "       Veteran_Status  Chronic_Condition  \n",
       "count   272652.000000      275236.000000  \n",
       "mean         1.897276           2.633329  \n",
       "std          0.499729           0.766646  \n",
       "min          1.000000           1.000000  \n",
       "25%          2.000000           3.000000  \n",
       "50%          2.000000           3.000000  \n",
       "75%          2.000000           3.000000  \n",
       "max          9.000000           3.000000  \n",
       "\n",
       "[8 rows x 44 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate descriptive statistics for the DataFrame, including count, mean, and standard deviation\n",
    "# Useful for understanding the distribution of numerical features\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated EDA with Sweetviz\n",
    "\n",
    "The `Sweetviz` library's `analyze` function was used to perform an automated exploratory data analysis (EDA) on the dataset. This function provides a comprehensive overview of the data, including:\n",
    "\n",
    "1. **Dataset Summary**:\n",
    "   - The shape of the dataset (number of rows and columns).\n",
    "   - Types of features (numerical or categorical).\n",
    "   - Missing values and unique value counts.\n",
    "\n",
    "2. **Feature Analysis**:\n",
    "   - For **numerical features**, it provides:\n",
    "     - Distributions (via histograms).\n",
    "     - Key statistics like mean, median, variance, and outlier counts.\n",
    "   - For **categorical features**, it includes:\n",
    "     - Frequency distributions and proportions.\n",
    "     - Bar charts for visualization.\n",
    "\n",
    "3. **Target Variable Insights**:\n",
    "   - If a target variable is provided, the function evaluates the relationship between each feature and the target.\n",
    "   - It highlights influential features and calculates correlations.\n",
    "\n",
    "4. **Comparison (if applicable)**:\n",
    "   - If multiple datasets (e.g., training and testing sets) are provided, the function compares them to identify differences in feature distributions.\n",
    "\n",
    "The resulting report is saved as an interactive HTML file, enabling a quick and intuitive review of the dataset's key properties. This tool significantly accelerates the initial data exploration process, allowing us to focus on deeper analysis and feature engineering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources for Sweetviz Analysis\n",
    "\n",
    "1. **[Official Sweetviz Documentation](https://github.com/fbdesignpro/sweetviz)**  \n",
    "   Provides comprehensive details on the library's capabilities, including dataset summaries, feature analysis, target variable insights, and dataset comparisons.\n",
    "\n",
    "2. **[\"SweetViz Library â€“ EDA in Seconds\" by Analytics Vidhya](https://www.analyticsvidhya.com/blog/2021/05/sweetviz-library-eda-in-seconds/)**  \n",
    "   Offers an in-depth tutorial on using Sweetviz for automated exploratory data analysis, highlighting its features and benefits.\n",
    "\n",
    "3. **[\"SweetViz: Streamlining EDA with Elegant Visualizations\" by Statistics Canada](https://statcan.github.io/aaw/en/1-Experiments/Notebooks/SweetViz_EN.html)**  \n",
    "   Discusses how Sweetviz simplifies the exploratory data analysis process through automated and interactive reports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Sweetviz analysis report for the dataset\n",
    "# This will include insights such as feature distributions, correlations, and relationships with the target variable\n",
    "report = sv.analyze(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and open the Sweetviz report as an interactive HTML file\n",
    "# The report provides a user-friendly way to explore the dataset visually\n",
    "report.show_html(\"Sweetviz_Report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swetviz Report Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sweetviz report provides a high-level overview of the dataset, summarizing its key characteristics. The dataset consists of **275,326 rows**, with **8 duplicate rows**, requiring approximately **96.9 MB of RAM**. It contains **44 features**, of which **9 are numerical** and **35 are categorical**.\n",
    "\n",
    "The automated report offers detailed insights into each feature:\n",
    "1. **Numerical Features**:\n",
    "   - Includes a comprehensive statistical summary, such as mean, median, standard deviation, and range.\n",
    "2. **Categorical Features**:\n",
    "   - Displays frequency distribution reports to highlight the prevalence of each category.\n",
    "\n",
    "Additionally, the report highlights missing values within each feature:\n",
    "- **Color Coding**: \n",
    "   - Low percentages of missing values are displayed in green for easy identification.\n",
    "   - High percentages are flagged in red to prioritize handling during data preprocessing.\n",
    "\n",
    "This analysis provides a strong foundation for identifying patterns, missing data, and potential areas for feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Columns with High Missing Values\n",
    "\n",
    "As the next step, we analyze the columns with the highest percentages of missing values. Based on the Sweetviz report, the following features were identified as having significant missing data:\n",
    "\n",
    "- **Pneumonia_Vaccination_Status**: 61%\n",
    "- **Caregiver_Major_Health_Problem**: 96%\n",
    "- **PSA_Test_Status**: 98%\n",
    "- **Mammogram_Status**: 50%\n",
    "- **Eye_Exam_Status**: 96%\n",
    "\n",
    "These columns will require careful handling during preprocessing, as their high missing percentages may impact model performance. Potential strategies include:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Variable: Chronic_Condition\n",
    "\n",
    "#### Distribution of Classes:\n",
    "The dataset reveals a significant class imbalance:\n",
    "- **81%** of individuals fall under `3.0` (no chronic condition).\n",
    "- **18%** fall under `1.0` (chronic condition present).\n",
    "- **1%** fall under `2.0` (special case, Yes, but female told only during pregnancy).\n",
    "\n",
    "This imbalance will require adjustments during modeling to avoid bias toward the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key Feature Associations:\n",
    "1. **Categorical Features**:\n",
    "   - The strongest association is observed with **Eye_Exam_Status** (Uncertainty Coefficient = **0.32**).\n",
    "   - Other notable features include:\n",
    "     - **General_Health**: **0.08**\n",
    "     - **Employment_Status**: **0.05**\n",
    "     - **Colonoscopy_Status**: **0.04**\n",
    "     - These features may represent preventive care behaviors and health indicators critical for predicting chronic conditions.\n",
    "\n",
    "2. **Numerical Features**:\n",
    "   - **Age** has the highest correlation with `Chronic_Condition` (Correlation Ratio = **0.24**).\n",
    "   - **Number_of_Children**: **0.13**\n",
    "   - **Primary_Health_Insurance_Source**: **0.03**\n",
    "   - Ageâ€™s correlation suggests a potential risk increase with age, consistent with prior medical literature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key Insights:\n",
    "The analysis highlights the importance of preventive behaviors and demographic factors in predicting chronic conditions. These insights will guide the feature engineering and model-building phases, ensuring the inclusion of relevant predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transition:\n",
    "After analyzing the target variable and identifying key feature associations, we now address missing values in the dataset. Proper handling of missing data is crucial, especially for features like `Eye_Exam_Status` and `Colonoscopy_Status`, which are strongly associated with `Chronic_Condition`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                                  0.000000\n",
      "Sex                                  0.000000\n",
      "Race                                 0.000000\n",
      "Education_Level                      0.000363\n",
      "Income_Level                         2.888794\n",
      "Marital_Status                       0.000727\n",
      "Employment_Status                    1.398073\n",
      "Number_of_Children                   2.093113\n",
      "Weight                               3.542778\n",
      "Height                               3.790565\n",
      "Housing_Status                       0.001453\n",
      "Smoking_Status                       0.000000\n",
      "Alcohol_Consumption                  0.000000\n",
      "Alcohol_Frequency                    0.000000\n",
      "Exercise_Status                      0.000000\n",
      "Sleep_Duration                       0.000363\n",
      "Asthma_Status                        0.000000\n",
      "Pneumonia_Vaccination_Status        61.279774\n",
      "General_Health                       0.000363\n",
      "Physical_Health_Poor_Days            0.000000\n",
      "Mental_Health_Poor_Days              0.000000\n",
      "Difficulty_Walking                   4.921958\n",
      "BMI_Category                        10.858681\n",
      "Arthritis_Status                     0.000000\n",
      "Coronary_Heart_Disease_Status        1.093970\n",
      "Stroke_Status                        0.000000\n",
      "COPD_Status                          0.000000\n",
      "Kidney_Disease_Status                0.000000\n",
      "Caregiver_Major_Health_Problem      95.596870\n",
      "Total_Physical_Inactivity            0.000000\n",
      "Depression_Status                    0.001453\n",
      "Primary_Health_Insurance_Source      0.000363\n",
      "Has_Personal_Doctor                  0.000000\n",
      "Could_Not_See_Doctor_Due_To_Cost     0.000000\n",
      "Last_Routine_Checkup                 0.000000\n",
      "Tetanus_Shot_Status                 10.116773\n",
      "Colonoscopy_Status                  34.814123\n",
      "Mammogram_Status                    50.144967\n",
      "PSA_Test_Status                     98.325074\n",
      "Flu_Shot_Status                      9.716026\n",
      "Eye_Exam_Status                     96.348225\n",
      "Last_Dental_Visit                    0.310279\n",
      "Veteran_Status                       0.938831\n",
      "Chronic_Condition                    0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of missing values for each column\n",
    "missing_percent = df.isnull().sum() / len(df) * 100\n",
    "print(missing_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we focus on identifying columns with **less than 10% missing values** and removing rows where these columns still have missing data. The reasoning behind this decision is rooted in the following principles:\n",
    "\n",
    "1. **Data Integrity**:\n",
    "   - Columns with minimal missing data are typically critical to preserve because they provide valuable information. Dropping rows with missing values ensures the data remains complete for these columns without significantly reducing the overall dataset size.\n",
    "\n",
    "2. **Minimal Information Loss**:\n",
    "   - Since less than 10% of values are missing, the number of rows affected by this operation is relatively small. This approach minimizes the impact on dataset size while maintaining high data quality.\n",
    "\n",
    "3. **Avoiding Imputation Bias**:\n",
    "   - Imputing values (e.g., with the mean, median, or mode) for these columns may introduce bias, especially when the missingness is not random (e.g., related to certain groups). By removing rows with missing data, we ensure the integrity of the remaining data.\n",
    "\n",
    "#### Supporting References:\n",
    "- *Kang, H. (2013)*: \"How to understand and utilize missing data\" explains that when the percentage of missing data is small, removing affected rows is often the simplest and most effective approach. ([Source](https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-13-1))\n",
    "- *Schafer, J. L., & Graham, J. W. (2002)*: Discuss best practices for handling missing data, noting that listwise deletion (row removal) is appropriate for small percentages of missingness. ([Source](https://doi.org/10.1037/1082-989X.7.2.147))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation:\n",
    "The following code identifies columns with less than 10% missing values, then drops rows with missing values in those columns. This ensures data quality and consistency moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with less than 10% missing values\n",
    "columns_with_few_missing = missing_percent[missing_percent < 10].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Sex', 'Race', 'Education_Level', 'Income_Level',\n",
      "       'Marital_Status', 'Employment_Status', 'Number_of_Children', 'Weight',\n",
      "       'Height', 'Housing_Status', 'Smoking_Status', 'Alcohol_Consumption',\n",
      "       'Alcohol_Frequency', 'Exercise_Status', 'Sleep_Duration',\n",
      "       'Asthma_Status', 'General_Health', 'Physical_Health_Poor_Days',\n",
      "       'Mental_Health_Poor_Days', 'Difficulty_Walking', 'Arthritis_Status',\n",
      "       'Coronary_Heart_Disease_Status', 'Stroke_Status', 'COPD_Status',\n",
      "       'Kidney_Disease_Status', 'Total_Physical_Inactivity',\n",
      "       'Depression_Status', 'Primary_Health_Insurance_Source',\n",
      "       'Has_Personal_Doctor', 'Could_Not_See_Doctor_Due_To_Cost',\n",
      "       'Last_Routine_Checkup', 'Flu_Shot_Status', 'Last_Dental_Visit',\n",
      "       'Veteran_Status', 'Chronic_Condition'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(columns_with_few_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where columns with less than 10% missing values still have missing data\n",
    "df = df.dropna(subset=columns_with_few_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step focuses on programmatically identifying columns with **over 10% missing values** and evaluating their impact on the dataset. Among these, columns with **more than 60% missing values** will be dropped entirely. The reasoning behind this approach is as follows:\n",
    "\n",
    "#### Impact of High Missing Values:\n",
    "- Columns with a high percentage of missing values (>60%) provide limited information and can introduce noise into the model.\n",
    "- Retaining such columns may lead to unreliable results and increased computational overhead.\n",
    "\n",
    "#### Defining Thresholds:\n",
    "- The **10% threshold** is used to identify and evaluate features with moderate missingness. These columns may require specific handling (e.g., imputation or encoding).\n",
    "- The **60% threshold** is chosen as a cutoff to eliminate features that are too incomplete to contribute meaningful insights.\n",
    "\n",
    "#### Balancing Data Retention and Quality:\n",
    "- Dropping columns with excessive missing data prevents bias and maintains the dataset's overall integrity while ensuring critical features are preserved.\n",
    "\n",
    "#### Supporting References:\n",
    "- **Van Buuren, S. (2018)**: Notes that features with high percentages of missing data (>50%) are often too incomplete to be useful and should be removed. ([Source](https://stefvanbuuren.name/fimd/))\n",
    "- **Little & Rubin (2019)**: Discuss strategies for handling missing data and emphasize that a balance must be struck between data retention and quality. ([Source](https://doi.org/10.1007/978-1-4899-7274-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with more than 10% missing values\n",
    "columns_with_high_missing = missing_percent[missing_percent > 10].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pneumonia_Vaccination_Status      61.279774\n",
      "BMI_Category                      10.858681\n",
      "Caregiver_Major_Health_Problem    95.596870\n",
      "Tetanus_Shot_Status               10.116773\n",
      "Colonoscopy_Status                34.814123\n",
      "Mammogram_Status                  50.144967\n",
      "PSA_Test_Status                   98.325074\n",
      "Eye_Exam_Status                   96.348225\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print columns with more than 10% missing values for further analysis or decision-making\n",
    "print(missing_percent[missing_percent > 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with more than 60% missing values\n",
    "columns_with_very_high_missing = missing_percent[missing_percent > 60].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with more than 60% missing values as they are unlikely to provide useful information\n",
    "df = df.drop(columns=columns_with_very_high_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to identify the columns that still have missing values and evaluate their importance in achieving the project's goal. Specifically, this involves determining how these features contribute to identify early patients with chronic diseases to reduce healthcare costs and implement effective preventive care strategies.\n",
    "\n",
    "By focusing on the remaining missing data, we ensure that all critical features are appropriately handled, maintaining the dataset's integrity and relevance for predictive modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns that still have missing values after dropping high-missing-value columns\n",
    "remaining_missing_columns = df.columns[df.isnull().any()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missingness in BMI_Category by Chronic_Condition:\n",
      "Chronic_Condition\n",
      "1.0     6.524040\n",
      "2.0    11.629603\n",
      "3.0     6.716666\n",
      "Name: BMI_Category, dtype: float64\n",
      "Missingness in Tetanus_Shot_Status by Chronic_Condition:\n",
      "Chronic_Condition\n",
      "1.0    0.432482\n",
      "2.0    0.437477\n",
      "3.0    0.446671\n",
      "Name: Tetanus_Shot_Status, dtype: float64\n",
      "Missingness in Colonoscopy_Status by Chronic_Condition:\n",
      "Chronic_Condition\n",
      "1.0     9.799862\n",
      "2.0    50.054685\n",
      "3.0    34.737732\n",
      "Name: Colonoscopy_Status, dtype: float64\n",
      "Missingness in Mammogram_Status by Chronic_Condition:\n",
      "Chronic_Condition\n",
      "1.0    49.767656\n",
      "2.0     0.437477\n",
      "3.0    47.212833\n",
      "Name: Mammogram_Status, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Analyze the percentage of missing values in remaining columns by the Chronic_Condition categories\n",
    "for column in remaining_missing_columns:\n",
    "    print(f\"Missingness in {column} by Chronic_Condition:\")\n",
    "    print(df.groupby(\"Chronic_Condition\")[column].apply(lambda x: x.isnull().mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the breakdown above, we derive the following insights regarding missing values in key columns:\n",
    "\n",
    "#### **Tetanus_Shot_Status**:\n",
    "- Rows with missing values in this column can be safely dropped as they constitute nearly **0% across all target variable categories**, making their impact negligible.\n",
    "\n",
    "#### **BMI_Category**:\n",
    "- Similarly, rows with missing values in this column can also be dropped, as the distribution of missingness is minimal and well-balanced across the target categories. This ensures no significant bias is introduced by removing these rows.\n",
    "\n",
    "#### **Colonoscopy_Status**:\n",
    "- This column reveals an **interesting pattern**:\n",
    "  - High percentages of missing values are observed for patients with `Yes` (**9.8%**) and `No` (**34.7%**) responses in the `Chronic_Condition` target variable.\n",
    "  - However, the group with `Yes (but during pregnancy)` has an extremely high percentage (**50%**).\n",
    "  - These insights are critical as they reflect differences in **preventive care practices** among patients and highlight gaps that could guide targeted interventions.\n",
    "\n",
    "#### **Mammogram_Status**:\n",
    "- A similar pattern is observed:\n",
    "  - For patients with `No` chronic condition, **47%** of values are missing, while missingness is almost negligible for patients who responded `Yes during pregnancy`.\n",
    "  - This column also reflects differences in **gender preventive care**, and should be highlighted when using over or under sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in the BMI_Category column\n",
    "# This column is considered critical, and any missing values are not acceptable\n",
    "df = df.dropna(subset=['BMI_Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in the Tetanus_Shot_Status column\n",
    "df = df.dropna(subset=['Tetanus_Shot_Status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the project's objective to **identify patients with chronic diseases**, reduce costs, and implement effective **preventive care strategies**, it is essential to understand our patients' behaviors. \n",
    "\n",
    "The current implementation of the survey allows patients to skip certain answers, which introduces missing values in key columns like `Colonoscopy_Status` and `Mammogram_Status`. Rather than dropping these columns due to missing values, we will account for this behavior by imputing the value **99**. This ensures:\n",
    "- The imputed value does not introduce a false relationship with existing categories in the column.\n",
    "- The behavior of skipped responses is retained for future analysis, preserving potential insights into **preventive care practices**.\n",
    "\n",
    "This approach ensures we do not lose valuable context while maintaining the integrity of the dataset for predictive modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the Colonoscopy_Status column with 99 as a placeholder\n",
    "# This ensures the model treats missing values explicitly\n",
    "df[\"Colonoscopy_Status\"] = df[\"Colonoscopy_Status\"].fillna(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the Mammogram_Status column with 99 as a placeholder\n",
    "# This ensures consistency and avoids dropping rows unnecessarily\n",
    "df[\"Mammogram_Status\"] = df[\"Mammogram_Status\"].fillna(99)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To track the changes to our dataset we will be creating a new Sweetviz report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Sweetviz analysis report for the dataset\n",
    "# This will include insights such as feature distributions, correlations, and relationships with the target variabler\n",
    "report = sv.analyze(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and open the Sweetviz report as an interactive HTML file\n",
    "# The report provides a user-friendly way to explore the dataset visually\n",
    "report.show_html(\"Sweetviz_Report_After_EDA.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_missing_columns = df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(remaining_missing_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the Preprocessed Data\n",
    "The final step in this notebook saves the cleaned and preprocessed dataset to a new CSV file named `feature_engineering.csv`. This file will be used in subsequent steps for feature engineering and model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 'feature_engineering.csv' has been created!\n"
     ]
    }
   ],
   "source": [
    "# Save the processed DataFrame to a new CSV file for the feature engineering step\n",
    "# This ensures the cleaned and preprocessed data is ready for further analysis or modeling\n",
    "df.to_csv(\"feature_engineering.csv\", index=False)\n",
    "\n",
    "# Confirm that the file has been successfully created\n",
    "print(\"The file 'feature_engineering.csv' has been created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Step: Ensuring Consistent Preprocessing for the Test Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test_original.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                                  0.000000\n",
      "Sex                                  0.000000\n",
      "Race                                 0.000000\n",
      "Education_Level                      0.000440\n",
      "Income_Level                         0.840347\n",
      "Marital_Status                       0.000440\n",
      "Employment_Status                    0.409186\n",
      "Number_of_Children                   0.606087\n",
      "Weight                               1.064498\n",
      "Height                               1.144929\n",
      "Housing_Status                       0.000440\n",
      "Smoking_Status                       0.000000\n",
      "Alcohol_Consumption                  0.000000\n",
      "Alcohol_Frequency                    0.000000\n",
      "Exercise_Status                      0.000000\n",
      "Sleep_Duration                       0.000000\n",
      "Asthma_Status                        0.000000\n",
      "Pneumonia_Vaccination_Status        18.628722\n",
      "General_Health                       0.000000\n",
      "Physical_Health_Poor_Days            0.000000\n",
      "Mental_Health_Poor_Days              0.000000\n",
      "Difficulty_Walking                   1.501813\n",
      "BMI_Category                         3.275684\n",
      "Arthritis_Status                     0.000000\n",
      "Coronary_Heart_Disease_Status        0.323920\n",
      "Stroke_Status                        0.000000\n",
      "COPD_Status                          0.000000\n",
      "Kidney_Disease_Status                0.000000\n",
      "Caregiver_Major_Health_Problem      28.907593\n",
      "Total_Physical_Inactivity            0.000000\n",
      "Depression_Status                    0.000000\n",
      "Primary_Health_Insurance_Source      0.000000\n",
      "Has_Personal_Doctor                  0.000000\n",
      "Could_Not_See_Doctor_Due_To_Cost     0.000000\n",
      "Last_Routine_Checkup                 0.000000\n",
      "Tetanus_Shot_Status                  3.084057\n",
      "Colonoscopy_Status                  10.583013\n",
      "Mammogram_Status                    15.102077\n",
      "PSA_Test_Status                     29.752774\n",
      "Flu_Shot_Status                      2.953082\n",
      "Eye_Exam_Status                     29.122074\n",
      "Last_Dental_Visit                    0.092737\n",
      "Veteran_Status                       0.276453\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "missing_percent = df_test.isnull().sum() / len(df) * 100\n",
    "print(missing_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68809, 43)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Sex', 'Race', 'Education_Level', 'Income_Level',\n",
       "       'Marital_Status', 'Employment_Status', 'Number_of_Children', 'Weight',\n",
       "       'Height', 'Housing_Status', 'Smoking_Status', 'Alcohol_Consumption',\n",
       "       'Alcohol_Frequency', 'Exercise_Status', 'Sleep_Duration',\n",
       "       'Asthma_Status', 'Pneumonia_Vaccination_Status', 'General_Health',\n",
       "       'Physical_Health_Poor_Days', 'Mental_Health_Poor_Days',\n",
       "       'Difficulty_Walking', 'BMI_Category', 'Arthritis_Status',\n",
       "       'Coronary_Heart_Disease_Status', 'Stroke_Status', 'COPD_Status',\n",
       "       'Kidney_Disease_Status', 'Caregiver_Major_Health_Problem',\n",
       "       'Total_Physical_Inactivity', 'Depression_Status',\n",
       "       'Primary_Health_Insurance_Source', 'Has_Personal_Doctor',\n",
       "       'Could_Not_See_Doctor_Due_To_Cost', 'Last_Routine_Checkup',\n",
       "       'Tetanus_Shot_Status', 'Colonoscopy_Status', 'Mammogram_Status',\n",
       "       'PSA_Test_Status', 'Flu_Shot_Status', 'Eye_Exam_Status',\n",
       "       'Last_Dental_Visit', 'Veteran_Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns with missing values <10% in the training dataset\n",
    "columns_with_few_missing_training = [col for col in df.columns if df[col].isnull().sum() < len(df) * 0.1]\n",
    "\n",
    "# Ensure the same columns exist in the test dataset\n",
    "columns_with_few_missing_test = [col for col in columns_with_few_missing_training if col in df_test.columns]\n",
    "\n",
    "# Drop rows in df_test with missing values in these columns\n",
    "df_test = df_test.dropna(subset=columns_with_few_missing_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows remaining after dropping rows with missing values in <10% columns: 20915\n"
     ]
    }
   ],
   "source": [
    "print(f\"Rows remaining after dropping rows with missing values in <10% columns: {df_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"Mammogram_Status\"] = df_test[\"Mammogram_Status\"].fillna(99)\n",
    "df_test[\"Colonoscopy_Status\"] = df_test[\"Colonoscopy_Status\"].fillna(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20915, 43)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows remaining after dropping columns: 20915\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values in the Tetanus_Shot_Status column\n",
    "df_test = df_test.dropna(subset=['Tetanus_Shot_Status'])\n",
    "df_test = df_test.dropna(subset=['BMI_Category'])\n",
    "\n",
    "print(f\"Rows remaining after dropping columns: {df_test.shape[0]}\")  # After final dropna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the Test Data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 'Post_EDA_test.csv' has been updated!\n"
     ]
    }
   ],
   "source": [
    "df_test.to_csv(\"Post_EDA_test.csv\", index=False)\n",
    "\n",
    "# Confirm that the file has been successfully created\n",
    "print(\"The file 'Post_EDA_test.csv' has been updated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20915, 43)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Sex', 'Race', 'Education_Level', 'Income_Level',\n",
       "       'Marital_Status', 'Employment_Status', 'Number_of_Children', 'Weight',\n",
       "       'Height', 'Housing_Status', 'Smoking_Status', 'Alcohol_Consumption',\n",
       "       'Alcohol_Frequency', 'Exercise_Status', 'Sleep_Duration',\n",
       "       'Asthma_Status', 'Pneumonia_Vaccination_Status', 'General_Health',\n",
       "       'Physical_Health_Poor_Days', 'Mental_Health_Poor_Days',\n",
       "       'Difficulty_Walking', 'BMI_Category', 'Arthritis_Status',\n",
       "       'Coronary_Heart_Disease_Status', 'Stroke_Status', 'COPD_Status',\n",
       "       'Kidney_Disease_Status', 'Caregiver_Major_Health_Problem',\n",
       "       'Total_Physical_Inactivity', 'Depression_Status',\n",
       "       'Primary_Health_Insurance_Source', 'Has_Personal_Doctor',\n",
       "       'Could_Not_See_Doctor_Due_To_Cost', 'Last_Routine_Checkup',\n",
       "       'Tetanus_Shot_Status', 'Colonoscopy_Status', 'Mammogram_Status',\n",
       "       'PSA_Test_Status', 'Flu_Shot_Status', 'Eye_Exam_Status',\n",
       "       'Last_Dental_Visit', 'Veteran_Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_Xtillion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
